{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xaerXUudi9pO"
   },
   "source": [
    "# CS51 Assignment 2: Algorithms and Simulation\n",
    "\n",
    "This assignment has two distinct parts in addition to a reflection: Part 1 allows you to practice your algorithmic thinking skills and Part 2 allows you to gain a deeper understanding of numerical simulations. Material relevant for Part 1 will be covered during CS51 weeks 3-5 (especially session 5.2), while material relevant for Part 2 will be covered during weeks 6 and 7 (especially session 7.1). \n",
    "\n",
    "This is an individual assignment. We will be checking for similarities among submissions and will take plagiarism seriously.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2r8WRqUvi9pP"
   },
   "source": [
    "## Part 1: Genetic Regression Algorithm  \n",
    "\n",
    "This portion of the assignment checks your understanding of Python code and algorithmic thinking. Your notebook contains a set of very poorly documented python functions. These functions attempt to use a genetic algorithm to find the regression line for a dataset by looking for the two coefficients of the line. For each function, you’ll write comments explaining what the function does step-by-step, and the roles they play in the genetic algorithm. You will have to spend a considerable amount of time playing with the code! Check out the Python tips section for helpful strategies.\n",
    "\n",
    "### 1. Function Description [#algorithms, optimization]\n",
    "\n",
    "#### 1.1 For each of the functions **A to E**, add in-line comments to explain what the code is doing line-by-line. In addition to in-line comments, write a few sentences that address the following points. (50-100 words per annotation).\n",
    "\n",
    "* Identify the aspect of a genetic algorithm that the function pertains to and explain why this aspect is important for optimization.  \n",
    "\n",
    "* Describe how the function accomplishes its task.  \n",
    "\n",
    "* Specify the inputs, outputs, and any major data structures involved.  \n",
    "\n",
    "\n",
    "#### 1.2 Missing function: Function F currently does nothing. Use a process of elimination to determine, then describe, which common element of a genetic algorithm is missing from this program and could become F. Detail why this element of the algorithm is important for finding an optimal solution. Then, fill in function F with working code that accomplishes this task and explain how it works.\n",
    "\n",
    "#### 1.3 Be sure to also consider the “main program” portion of the code. Add comments and explain what this part does and how it connects to the functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "btPK66Coi9pQ"
   },
   "outputs": [],
   "source": [
    "### Genetic algorithm to fit a regression line of the form y=ax+b to a 2-variable \n",
    "#dataset.\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# load the data\n",
    "my_data_file = 'temp_data.npy'\n",
    "data = np.load(my_data_file)\n",
    "\n",
    "# parameters \n",
    "initial_pop_size = 100\n",
    "mutation_rate = 0.05\n",
    "num_generations = 10 \n",
    "chromosome_length = 2\n",
    "num_survivors = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pgSADUyoi9pU"
   },
   "outputs": [],
   "source": [
    "def A(): #defining the function which takes no input\n",
    "    \n",
    "    gene_pool = np.linspace(-1,80,num = 5000) #creates a sequence of 5000 evenly \n",
    "    #spaced numbers within the interval [-1 to 80]. So the first number in the \n",
    "    #array is -1, the last is 80, and the remaining 4998 values are evenly \n",
    "    #spread between -1 and 80. \n",
    "    \n",
    "    dimensions = (initial_pop_size, chromosome_length) #sets the dimensions for \n",
    "    #the array.\n",
    "    \n",
    "    return np.random.choice(gene_pool, size=dimensions, replace=False) #generates \n",
    "    #and returns a random sample population without replacement from the array \n",
    "    #\"gene_pool\" with the size of the dimensions (100 rows with two columns). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wiL8sE9Qi9pX"
   },
   "source": [
    "**Function A** is responsible for generating the initial population. First, it creates an array of 5000 numbers evenly spread between -1 and 80 (inclusive). Then it finds the initial population by drawing samples from the 5000 numbers using the np.random.choice function. According to the parameters and the dimensions, the shape of the array is (100, 2). Hence, there will be 100 chromosomes each with two genes, and each element is one of the 5000 numbers generated initially. Furthermore, the sampling is random which means that if the code is rerun, the initial population will change. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BbTmkKXWi9pY"
   },
   "outputs": [],
   "source": [
    "def B(coefficients): #defines a function which takes coefficients as input. \n",
    "    k = len(data) #sets k equal to the length of the data/number of items in the data. \n",
    "    tot = 0 #sets the initial total equal to 0. \n",
    "    \n",
    "    for j in range(k): #creates a for loop that iterates over the range of k (the \n",
    "    #length of the data). \n",
    "        \n",
    "        y = coefficients[0] * data[j,0] + coefficients[1] #finds the y-value by \n",
    "        #multiplying the first set of elements of the coefficients array with the \n",
    "        #corresponding x-element from the real dataset array. Then, the second set \n",
    "        #of elements from the coefficients array is added. The result is then \n",
    "        #assigned to the variable y.\n",
    "        \n",
    "        res = data[j,1] - y #finds the residuals by taking the y value of the real \n",
    "        #data array and subtracting the corresponding y value found in the above \n",
    "        #line. Then, the results are contained within \"res\" as an array. \n",
    "        \n",
    "        tot += res**2 #calculates the total sum of squared residuals by summing the \n",
    "        #squares of the individual residuals found in each iteration. \n",
    "    \n",
    "    return tot/k #returns the sum of squared residuals divided by k/the length of \n",
    "    #the data to find the mean squared residuals. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pp1T_mFCi9pb"
   },
   "source": [
    "**Function B** takes the array \"coefficients\" as input and returns the mean squared residuals which allow us to find the fitness values/expected error which we can then try to minimize later by changing the parameters.\n",
    "\n",
    "The algorithm uses the regression line equation to find the predicted y-value by taking the first chromosome of the coefficients data, multiplying it by the real dataset gene value (corresponding to the element in the current iteration's row [j] and in the first column). Afterward, it adds the value in the coefficient data's second row. Next, it calculates the residuals by taking the current y-value and subtracting the computed y-value. Then, it sums the squares of the residuals. \n",
    "\n",
    "This process is repeated in the range of k (the real data's length) to find the total sum of squared residuals. Lastly, it divides the total sum of squared residuals by the length of the data to compute the mean squared residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xtJndQcWi9pc"
   },
   "outputs": [],
   "source": [
    "def C(): #defines a function which takes no input.\n",
    "    fitlist = [] #creates an empty list for the fitness values of each solution. \n",
    "    \n",
    "    for x in range(len(current_pop)): #creates a for loop which iterates over the \n",
    "        #range of \"current_pop\" (the population generated by function A).\n",
    "        \n",
    "        fitlist.append(np.array([x,B(current_pop[x])])) #makes an array of the x \n",
    "        #values and the residuals values found by inputting the dataset \"current_pop\" \n",
    "        #into function B. The array is then appended to the fitness list. \n",
    "    \n",
    "    return np.array(fitlist) #returns the fitness list as an array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "omKXqXQPi9pf"
   },
   "source": [
    "**Function C** is responsible for assembling a list of the fitness values. It starts by generating an empty list which will be used to store the fitness values. Through a for loop that iterates over the range of the \"current_pop\" dataset, the function takes the fitness values calculated by function B and appends them to the fitness list. Lastly, it returns the fitness list as an array with the first column being each x value (the range of the \"current_pop\" dataset's length) and the second column being the corresponding fitness value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R7akJrFxi9pg"
   },
   "outputs": [],
   "source": [
    "def D(): #defines a function which takes no input\n",
    "    \n",
    "    random_selection = np.random.choice(range(len(fitness_vector)), \\\n",
    "    num_survivors//2, replace=False) \n",
    "    #the function selects random numbers within the range of the length of the \n",
    "    #fitness_vector generated with function C without replacement. The number \n",
    "    #of chosen elements is equal to the number of survivors divided by two and \n",
    "    #rounded down to the nearest integer. The elements are then assigned to the \n",
    "    #random_selection variable.   \n",
    "\n",
    "    best = np.argmin(fitness_vector[random_selection,1]) #finds the index within \n",
    "    #the \"random_selection\" array that contains the element with the smallest \n",
    "    #fitness value (from the fitness_vectors) and assigns it to the variable \"best\". \n",
    "    \n",
    "    best_index = random_selection[best] #takes the random_selection array and goes \n",
    "    #to the element at \"best\" index. Then this element is assigned to \"best_index\". \n",
    "    \n",
    "    return current_pop[int(fitness_vector[best_index][0])] #in the \"fitness_vector\" \n",
    "    #array, it finds the element in the \"best_index\" row and first column [0]. \n",
    "    #Then it goes to the index in the \"current_pop\" array that has the element's \n",
    "    #value and returns the chromosome at this location.       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MqIN7T8Ci9pi"
   },
   "source": [
    "**Function D** takes no input and ultimately outputs the chromosome with the smallest fitness value from a random sample. This part of the algorithm optimizes the solution, as the process is repeated several times in the main program.  \n",
    "\n",
    "First, it takes a random sample of numbers within the range of fitness_vector's length and assigns them to \"random_selection\". Then, it finds the index of the smallest fitness value in the \"random_selection\", goes back to the original list (fitness_vector) at this index, and assigns the value at this location to \"best_index\". Lastly, it returns the chromosome value that is at the \"best_index\" index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZahYoYiSi9pj"
   },
   "outputs": [],
   "source": [
    "def E(): #defines a function which takes no input. \n",
    "    \n",
    "    duplicate_size = len(new_population) - len(survivors) #takes the length of the \n",
    "    #\"new_population\", subtracts the length of the ”survivors\", and assigns this \n",
    "    #value to \"duplicate_size\".\n",
    "    \n",
    "    duplicate_survivors = np.zeros((duplicate_size, chromosome_length)) #creates an \n",
    "    #array filled with zeroes with the dimensions of \"duplicate size\" (rows) versus \n",
    "    #chromosome_length (columns).\n",
    "    \n",
    "    for x in range(chromosome_length): #creates a for loop which iterates over the \n",
    "    #range of the chromosome_length.\n",
    "        \n",
    "        duplicate_survivors[:, x] = np.repeat(survivors[:, x], 4, axis=0) #repeats \n",
    "        #the survivor list from the beginning element to the current x (iteration) \n",
    "        #element four times. These elements are then assigned to \"duplicate_survivors\"\n",
    "        #from the initial index to the index of the current iteration.  \n",
    "        \n",
    "        duplicate_survivors[:, x] = np.random.permutation(duplicate_survivors[:, x]) \n",
    "        #randomly permutates the \"duplicated_survivors\" array from the first element \n",
    "        #to the current x (iteration) element. The permuted array is then reassigned \n",
    "        #to \"duplicated_survivors\".\n",
    "        \n",
    "    return duplicate_survivors #returns the duplicated survivors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Ezqn5f-i9po"
   },
   "source": [
    "**Function E** finds the next generation by applying crossover and permutation among the surviving chromosomes. By using genes with the least fitness value (smallest error), it optimizes the offsprings and further generations.  \n",
    "\n",
    "First, it finds the difference in length between the \"new_population\" and the \"survivors\" array. Then it prepares for the crossover by generating an array filled with zeroes which is later assigned values in the for loop. Here, different lengths of the \"survivors\" array are duplicated four times and then permutated. This process is then repeated in the range of the \"chromosome_length,\" and lastly the final \"duplicate_survivors\" array is returned.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-peBLqMji9pp"
   },
   "outputs": [],
   "source": [
    "from numpy.random import choice #importing package that allows to randomly generate \n",
    "#a number based on probability weights.\n",
    "\n",
    "def F(array): # defines a function which takes an array as the input. \n",
    "    \n",
    "    elements = [0, 1] #generates two elements where 0 corresponds to no mutation and \n",
    "    #1 to mutation. \n",
    "    weights = [1 - mutation_rate, mutation_rate] #sets the chance of not mutating and \n",
    "    #mutating (taken from the mutation_rate variable). \n",
    "\n",
    "    numrows = (len(array)) #finds the number of rows in the data array.\n",
    "    numcolumns = (len(array[0])) #finds the number of columns in the data array.\n",
    "    \n",
    "    for i in range((len(array))): #iterates through each row. \n",
    "        \n",
    "        for j in range((len(array[0]))): #iterates through each column. \n",
    "\n",
    "            mutate_number = choice(elements, p = weights) #generates a 0 or 1 which \n",
    "            #determines if the current element will be mutated. \n",
    "        \n",
    "            if mutate_number == 1: #if the generated number is equal to 1, the \n",
    "            #element will mutate. \n",
    "            \n",
    "                original_value = array[i, j] #assigning the current element's index \n",
    "                #to a variable. \n",
    "\n",
    "                random_index1 = np.random.randint(0, numrows) #generates a random \n",
    "                #row from the data array.\n",
    "                random_index2 = np.random.randint(0, numcolumns) #generates a random \n",
    "                #column from the data array.\n",
    "\n",
    "                random_value = array[random_index1, random_index2] #finds the value \n",
    "                #of the element at the random row and column and assigns this value \n",
    "                #to a variable. \n",
    "\n",
    "                array[i,j] = random_value #changes the current element's value to \n",
    "                #the value of the randomly selected element.\n",
    "\n",
    "                array[random_index1, random_index2] = original_value #changes the \n",
    "                #randomly selected element's value to the value of the current \n",
    "                #element (to avoid that a value will be repeated several times).\n",
    "\n",
    "    return array #returns the mutated array. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O6JL7-QCi9ps"
   },
   "source": [
    "**Missing part:**\n",
    "\n",
    "The genetic algorithm is missing the mutation part which I have implemented through function F. Mutation is important in a genetic algorithm because it introduces and maintains diversity. Furthermore, it can help optimize the result by introducing different solutions that can help the algorithm arrive at a better solution. \n",
    "\n",
    "Function F results in swap mutation which happens when two genes are randomly selected and swapped. First, I had to implement the mutation rate which has been done by generating either a 0 or 1 for each gene where 0 corresponds to not mutating and 1 to mutating. Here, the chance of getting a 1 is equal to the mutation rate and the chance of getting a 0 is one minus the mutation rate. \n",
    "\n",
    "If a 1 is generated, the algorithm enters an if statement that performs the mutation. Within this statement, it stores the current element's original value in \"original_value\". Next, the algorithm chooses a random row and column (an index) from the data array by using the \"np.random.randint\" function. Then, it goes to the random index and stores the value in \"random_value\". Afterward, it changes the current element's value to the value of the randomly generated element, and the randomly generated element's value to the current element's value (they swap their values). The mutation process is then repeated for each element where a 1 is generated, and lastly it returns the mutated array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ejgKKFfXi9pt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best solution is [ 0.70134027 67.13462693]\n",
      "with error equal to approximately 30.401536474940066\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "# Start of main program\n",
    "current_pop = A() #sets the current population by calling on function A that \n",
    "#generates and returns a random sample population. \n",
    "new_population = np.zeros((num_survivors * 5, chromosome_length)) #returns an \n",
    "#array filled with zeroes with the length (number of rows) of five times the \n",
    "#number of survivors and number of columns equal to the chromosome length (2). \n",
    "\n",
    "# main loop\n",
    "for i in range(num_generations): #sets up a for loop which iterates in the range of \n",
    "    #the number of generations (0,10).\n",
    "    \n",
    "    fitness_vector = C() #creates a fitness vector by calling function C. \n",
    "    survivors = np.zeros((num_survivors, chromosome_length)) #returns an array \n",
    "    #filled with zeroes with the length/number of rows equal to of the number of \n",
    "    #survivors and the number of columns equal to the chromosome length (2). \n",
    "\n",
    "    for n in range(len(survivors)): #sets up a for loop that iterates in the range \n",
    "        #of the length of the survivors array. \n",
    "        survivors[n] = D() #calls on function D to generate an array of the \n",
    "        #surviving chromones.\n",
    "    new_population[:len(survivors)] = survivors #takes the new_population array \n",
    "    #filled with zeroes and places the survivor values in it. Where the first \n",
    "    #value is placed on the first index of the list and the last is placed on \n",
    "    #the index equal to the survivors list. \n",
    "    \n",
    "    new_population[len(survivors):] = E() #calls on function E to take initiate \n",
    "    #the crossover process. The chromomes generated in this process is then \n",
    "    #added to the new_population list starting from the index next to the last \n",
    "    #filled. \n",
    "    \n",
    "    new_population = F(new_population) #calls on function F to initiate the \n",
    "    #mutation process and reassign it back to \"new_population\".\n",
    "    \n",
    "    current_pop = new_population #creates the next generation by assigning making \n",
    "    #the current population the new population.\n",
    "    new_population = np.zeros((num_survivors * 5, chromosome_length)) #returns an \n",
    "    #array filled with zeroes with the length (number of rows) of five times the \n",
    "    #number of survivors and number of columns equal to the chromosome length (2). \n",
    "\n",
    "fitness_vector = C() #creates a fitness vector by calling on function C.\n",
    "best_solution = current_pop[np.argmin(fitness_vector[:,1])] #generates the best \n",
    "#solution (min. fitness value) within the current population.\n",
    "print(\"The best solution is\", best_solution) #prints the best solution. \n",
    "print(\"with error equal to approximately\", B(best_solution)) #prints the approximate \n",
    "#error. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bud3Sc2Bi9pv"
   },
   "source": [
    "**Main Program:**\n",
    "\n",
    "The main program combines all the functions to form the genetic algorithm with the purpose of optimizing the regression line. First, it calls on Function A to generate the initial population of chromosomes (points). Then it produces an array filled with zeroes which will later contain the new population. Next, in the initial for loop, it calls on Function C to create an array which has the fitness values (residuals) found with the use of Function B. Afterward, it sets up another array filled with zeroes which is later used for the surviving chromosomes. \n",
    "\n",
    "Then the algorithm enters another for loop which calls on function D to generate the array of surviving chromosomes (the ones with the lowest fitness values/low residuals). These chromosomes are then placed in an array for the new population. Afterward, it performs crossover and mutation by calling on Function E and F respectively. Finally, the current population is changed to the newly generated population, and the \"new_population\" array is made ready for a new generation by filling it with zeroes again. \n",
    "\n",
    "The genetic algorithm repeats the process of finding the best fitness values among a random sample of the fitness values (Function B, C, and D), performing crossover (Function E), and performing mutation (Function F) in the range of the number of generations. As a result, the algorithm continues to optimize the regression line for each new generation it creates. \n",
    "\n",
    "Lastly, the algorithm prints the best solution with the lowest fitness value/lowest residuals. Here, the numbers indicate the two coefficients of the regression line. Additionally, it also prints the approximated error of the line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0StffJhLi9px"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5399259393210745, 70.70997220684585)\n"
     ]
    }
   ],
   "source": [
    "# scipy regression function to compare with the genetic algorithm's solutions\n",
    "from scipy import stats \n",
    "print(stats.linregress(data)[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yctx4pKdi9p2"
   },
   "source": [
    "### 2. Overview [#optimization, #algorithms, #regression]\n",
    "\n",
    "### 2.1 Write a paragraph to explain what the parameters at the top of the script are. By experimenting with varying parameter values, determine what values produce solutions that are closest to the actual solution most efficiently. Why do you think this is?  [~200 words]  \n",
    "\n",
    "The task of the program is to reflect the process of natural selection in which the fittest chromosomes are used for reproducing the offsprings for the following generation. In this case, we are trying to optimize a regression line based on each point's fitness values. Here, we prefer a lower fitness value because it corresponds to smaller residuals. To optimize, the program goes through a process of determining the fitness values, performing crossover among the best points in a random sample, and mutating by swapping individual values. The algorithm performs this process several times until it reaches the desired number of generations. Lastly, the program outputs the two coefficients of the regression line corresponding to the slope and the y-intercept along with the approximated error of the regression line. Hence, the algorithm optimizes by going through a process several times where each iteration improves the solution a bit more. \n",
    "\n",
    "Furthermore, by using \"scipy stats,\" we can compare the genetic algorithm's solution to the optimal solution which gives us insight into the performance of the genetic algorithm. \n",
    "\n",
    "### 2.2 Write a paragraph that gives an overview of how this program solves the given task and what the output represents.  [~200 words]:\n",
    "\n",
    "The \"initial_population\" defines the number of chromosomes in the initial population. \"Mutatiom_rate\" sets the frequency of a single gene mutating. \"Num_generations\" determines how many generations the algorithm creates, corresponding to the number of times it replaces a current population by an optimized one. The \"chromosome_length\" is how many genes each chromosome has. Lastly, the \"num_survivors\" determines how many chromosomes survive with each new generation.  \n",
    "\n",
    "The mutation rate should be small, to produce a solution close to the actual one (0.05 or lower). However, there should still be some mutation as it creates diversity and the possibility for better solutions that the algorithm might not find otherwise. Furthermore, I found that increasing the initial population made the error smaller. This might be the case because there are more gene values and thus additional lower fitness values that can be chosen. However, there will also be more high fitness values which can be selected. Therefore, I increased the number of generations because it makes the program go through the optimization process more times. As a result, for each generation, the coefficients of the regression line is improved and the error becomes smaller.\n",
    "\n",
    "### 3. Optional challenges (basic):\n",
    "\n",
    "For any attempted optional challenge, also indicate which HC(s) you are applying and why your solution constitutes a strong application.\n",
    "\n",
    "### 3.1 Modify the program to include a visualization of how the error/fitness changes with each subsequent generation. Interpret this however you like, but make sure to include a detailed explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab_type": "text",
    "id": "Dg5Hjm0Oi9p3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best solution is [ 0.78235647 66.69713943]\n",
      "with error equal to approximately 36.035978249493034\n"
     ]
    }
   ],
   "source": [
    "#Note: I have added comments in the places where I have modified the code \n",
    "#and left out the comments added above in 1.3 to make the modifications \n",
    "#clearer.\n",
    "\n",
    "from matplotlib.pylab import plt #package for plotting \n",
    "\n",
    "current_pop = A()\n",
    "new_population = np.zeros((num_survivors * 5, chromosome_length))\n",
    "\n",
    "count = 0 #setting a counter that can be used to generate each x-value for \n",
    "#the plotting. \n",
    "fitness_x = [] #generating an empty list for the x-values (each generation). \n",
    "fitness_y = [] #generating an empty list for the y-values (the error/fitness).\n",
    "\n",
    "for i in range(num_generations):\n",
    "    \n",
    "    fitness_vector = C()\n",
    "    survivors = np.zeros((num_survivors, chromosome_length))\n",
    "    for n in range(len(survivors)):\n",
    "        survivors[n] = D()\n",
    "    new_population[:len(survivors)] = survivors\n",
    "    new_population[len(survivors):] = E()\n",
    "    \n",
    "    new_population = F(new_population)\n",
    "    \n",
    "    current_pop = new_population\n",
    "    new_population = np.zeros((num_survivors * 5, chromosome_length))\n",
    "    \n",
    "    \n",
    "    current_best_index = np.argmin(fitness_vector[:,1]) #finding the index that \n",
    "    #contains the lowest error/fitness value within the current generation.\n",
    "    current_best_fitness = fitness_vector[current_best_index,1] #finding the \n",
    "    #fitness value at the current_best_index.\n",
    "    \n",
    "    count += 1 #generating the current x-value. \n",
    "    fitness_x.append(count) #appending the x-value to the x-value list. \n",
    "    fitness_y.append(current_best_fitness) #appending the lowest error/fitness \n",
    "    #value for the current generation to the y-value list.\n",
    "\n",
    "#plotting the x- and y-values with the use of matplotlip.\n",
    "plt.plot(fitness_x, fitness_y,) #defining the axis. \n",
    "plt.ylabel(\"Error/Fitness\") #y-label\n",
    "plt.xlabel(\"Generation\") #x-label\n",
    "plt.title(\"Change in Error/Fitness Value for Each Generation\") #title\n",
    "plt.show() #showing the plot\n",
    "\n",
    "\n",
    "fitness_vector = C()\n",
    "best_solution = current_pop[np.argmin(fitness_vector[:,1])]\n",
    "print(\"The best solution is\", best_solution)\n",
    "print(\"with error equal to approximately\", B(best_solution))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "I have modified the code, to make it output a graph that shows the change in the error/fitness value for each further generation. To do so, I first created two empty lists one which will contain each generation number and each fitness value respectively. Additionally, I created a variable which counts each time a new generation is created, and these counts are then appended during the for loop. At the same time, after each generation is found, the error is appended to the list with fitness values. The algorithm does this by finding the index of the current best solution, going to this index, and then adding the value to the list. Lastly, I plot and format the diagram with the use of the matplotlib library. \n",
    "\n",
    "After running the code several times, I can see that the general trend for the diagram is that the error is high in the beginning, decreases quickly, and then evens out/stays constant for the rest of the generations. This pattern might happen because the genetic algorithm can quickly \"kill\" the worst chromosomes but then reaches a plateau where it is not able to decrease the error more. The latter might be improved by having more generations as this would further minimize the error.\n",
    "\n",
    "**#algorithms:** I identified an appropriate way to code an algorithm which captures each generation number along with corresponding error and places them in a list. As a result, I generated a list of x-values and y-values that can be used for graphing.  Furthermore, I explained each step of the algorithm both through in-line comments and in the text above. \n",
    "\n",
    "**#dataviz:** I have generated a data visualization that is useful for getting a sense of how the error changes with each generation. Furthermore, I have properly formatted the figure and interpreted the trends seen in the in. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JAjvi6Cti9p4"
   },
   "source": [
    "\n",
    "#### 3.2 Optimize the code: There are many aspects of the code that could be improved. Choose one part of the code and describe in as much detail as possible a way in which it can be optimized. Then, implement your optimization. Be clear about what you are optimizing for and how your proposal accomplishes this. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vV0e3fm3i9p4"
   },
   "source": [
    "Edit this cell to answer part 3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hcW2Szp8i9p5"
   },
   "source": [
    "### 4. Optional challenges (more advanced):\n",
    "For any attempted optional challenge, also indicate which HC(s) you are applying and why your solution constitutes a strong application.\n",
    "\n",
    "### 4.1 Modify the program to do multiple variable regression; that is, allow more predictor variables and find the regression equation that best fits the data. This needs to include first finding a dataset to test the program on and comparing the results of your algorithm to those that can be produced with a library regression function.\n",
    "\n",
    "I tried to complete this challenge, but I think that there is something wrong or missing in my code since the error is quite high and the coefficients are not close to the ones found with the library function (see the end of the code). If possible, it would be great with some feedback or hints about where there might be some problems so that I can try to solve this challenge later. \n",
    "\n",
    "Although I do not think I fully solved the challenge, I still learned how to make .npy type files, how to use the linear regression function in the \"sklearn\" library, and the process of trying to implement multiple regression. Thus, I believe that I used **#selfawareness** because I assessed my strengths and decided to do the code to challenge myself. However, I also took my weaknesses and the time constraints into account by determining when I should stop and instead consult other sources for help. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab_type": "text",
    "id": "L0uNlaF3i9p6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEWCAYAAACwtjr+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XucXHV9//HXe2cBkVu4BApJMCARBSoRIgTRiiAQ8BKsiOCFiLRRLlUqrYC1haq0aFUsiihCJLFKQFCJ/cViRAG13MJFLiLNElGWxBAIkAAKJvn8/vh+h5xMzlx2d2aHbN7Px2MeO/M5t++ZMzuf+V7OOYoIzMzMOqmn2wUwM7ORz8nGzMw6zsnGzMw6zsnGzMw6zsnGzMw6zsnGzMw6zsnGAJD0Xkk/7nY5OkXSQ5Le3IXtHiSpf7i3O1CSNpX0Q0lPSfput8tTj6TrJf1Nt8sxXEbS/6WTzTDJX3Z/lPR04fGVYdr2eyR9R9J4SVFThl8BRMS3I+KwwjIhabfhKF8zks6SdGNJfDtJz0vaqxvlKpRjP0lzJT0paZmkWyWd0M0yDcLRwA7AthHxrqGuLCfZ1TWftaclHTD0og6oHFtI+mL+/3tG0u8lXSVpv+EsRysK/5+91Vjt/+X6zMlmeL0tIjYvPE4tm6n4YWsUa6Rm/iOBuYXXowpl2Hsg6+2SbwGvk7RLTfxY4J6IuLcLZQIgf3n+FLgB2A3YFjgJOKJbZRqklwH/FxErB7pgg8/moprP++YRcdPQijmgcm1COjZ/CbwV2BJ4FTCb9D8xrCRVhnubLyoR4ccwPICHgDfXmfYB4JfA+cAy4DN1Yj3AJ4HfAY8Cs4Ct8jrGAwGcCPweuDHHe4AlwHaFeXrrlOEX+fmNeb5ngKeBdwMHAf3A6Xnbi4ETCstvAnw+b3sJ8DVg0zxtO+C/gSfzvvwc6MnTzgAeAVYADwCH1HmPfgz8S03sVuAj+fnLSV8sjwOPAd8mJdV13n/gMuAzhWkHAf2F1zsBVwNLgd9Wt1GnXL8ALmwwvdn79hbgTmA58DBwTmFa9XhNy+/rY8A/FaZvCswEngDuBz4+mP0A/hV4HvhzPt4nMojPWtl+N3hfTshlXgEsBD5UM30qcFd+Xx4EpuT49cCnSf8bK/LnYrs62/ib/H5v1uR/85XAvPzZfAA4pjDtMuBC4P/l7d0CvHwAy15E+qH3DPDmJsf79/l9fTo/DqDwf5nneR1wG/BU/vu6wrSW35tuPLpegA3lQfNksxL4O6A3f4mUxT4I9AG7ApsD3wO+lddR/QKYBWzGmi/6ycBNNfM0TDb5dQC7FV4flMvzKWAj0i/DZ4Gt8/QvAXOAbYAtgB8C/56n/Tsp+WyUH28ABOye/+F2KpTv5XXeo/cCCwqvdyd9QY7Or3cDDiUlvdGkhPmlsvefBsmG9CV7O/AvwMb5vV4IHF5SppcCq4A3NTjuzd63g0i/vHuAV5MS9VE1x+sb+fjvDTwHvCpPP49Uo9oaGAvcPZj9yPOfA/xX4fWAP2sl+90o2byF9ANBwBvze7JPnrYf6cv00LwfY4BX5mnXk5LPK/J7cj1wXp1tzAYua/J/uRnpM3gC6f9sH1JS37PwWVmWy9RL+hEzewDLPgUcmPfjJS0e795C+T7Amh+B25B+WLw/b++4/Hrbgb43XfkO7HYBNpQH6cvuadKv++rjbwsfqN/XzF8Wuw44ufB6d9Kv0d7CB3XXmmU+Dfxzfl6dp1iGfyhsr1my+WPNP8KjpGQm0i+34i++A4Df5uefAq4pri/Hd8vreDOwUZP376WkX4Ovy6/PBa5pMP9RwJ01738ryWb/kvf9LOCbJdsYk9+nVzYoR933rc78XwLOrzleYwvTbwWOzc/XSh6kX/ID3o887RzWTjYD/qyV7Pfqms/ak9SpZQA/AD6an3+9+h6UzHc98MnC65OB/6kz708ofNkCE3MZlgMP5Ni7gZ/XLPd14OzCZ+WSwrQjgd8MYNlZTT7XZce7XrJ5P3BrzfI3AR8Y6HvTjceA+gFsyI6KiJ/UmfZwC7GdSM0aVb8j/fPv0GCZI4HpNbHtYhBt88DjNcs9S/rVO5qUDG6XVJ0moNpG/R+kL7Mf5+kXR8R5EdEn6bQ8bU9J1wIfi4hFtRuOiGfzKKnjJd1Equl87IWNSdsDF5BqTVuQfjk+MYh9fBmwk6QnC7EKqemv1hOkL9Qdgd80WGe99w1J+5NqKHuRaiCbALWjwf5Qtizp81A83sXnA9mPMoP5rNVaFBFjyyZIOgI4m/QrvIf0+bknTx7H2n2Mteq9H7UeJx0bACLiLmBUHpV4SQ6/DNi/5n3qJfUTNtteK8uu9R61eLzrqT0m5NdjWihr13mAwItHtBBbRPqAV+1MaqJZUraMpL8g/bPd0aYy1vMY6df7nhExKj+2iojNASJiRUScHhG7Am8DPibpkDztOxHxetJ+BfDZBtuZCRxDal7ZgtQPVPXveflXR8SWwPtICa/MM6Qvt6q/KDx/mFQjG1V4bBER63QoR8SzpF+W72xQ5ma+Q2p+HBcRW5GaG+uVu9ZiUvNZ1bjC85b3o44BfdYGInfcX03q49shIkaRkkt1vx8mNbEN1XXAYZI2azDPw8ANNe/T5hFxUgvrb2XZ2veo0fFu9n7WHhNIx+WRFsradU4265fLgb+XtIukzYF/A65oUEs5klSNHsyXwhJSe31TEbGa1K9wfq5hIGmMpMPz87dK2k2pWrOc1M+xStLukg7OXz5/IiWsVQ029XNSM8jFpHbz5wvTtiA3U0oaA/xjg/XcBRwpaZuckE8rTLsVWC7pjHzuSUXSXpJeW2ddHwc+IOkfJW2b93dvSbMbbL9oC2BZRPwpD8d9T4vLAVwJnCVp67zPxdGNA92PWgP9rA1E9Rf9UmBlruUUh/deCpwg6RBJPfmz9MpBbGcWKSF/P+97RdJLgEmFef4beIWk90vaKD9eK+lVLax/MMs2Ot5LSTXlev93c/P23iOpV9K7gT1Y+0fXi5aTzfD6Yc05B98f4PIzSFX0G0mji/5EGkBQT+2Q54E4B5iZzx05poX5zyB1KN8saTmpvXz3PG1Cfv00qSbw1Yi4nvSFcx6pZvQHYHvgE/U2kJPmLNKvu1k1k/+V1EH7FGnk0PcalPVbwK9I/Tg/Bq4obGMVqfY1kfQeP0ZqctmqTpn+Fzg4PxZKWkZKhq2+7ycDn5K0gtSZf2WLy0HqC+vP5fwJcBVpAMGA96PEQD9rZXYqOc/mnRGxAvgIaV+fIH3hzqkuFBG3kjrdzycdzxtY9xd9UxHxJ+BNwK9Jn4nlpBFjryXVkMllOYw0jH4R6XP4WdJns9n6B7Ns3eOda8rnAr/M/3eTa7b3OGkI9+mkJsKPA2+NiMealfXFQIP70Wsvdvnchz+QOu2f6nZ5rPMknUQaPPDGbpfFrJZrNiPXNqRRaE40I5SkHSUdmJuadif94h1obdlsWLhmY7aekvQyUvPQLqS+rNnAWTV9WWYvCk42ZmbWcW5GMzOzjvNJndl2220X48eP73YxzMzWK7fffvtjETG62XxONtn48eOZP39+t4thZrZekVR7VYNSbkYzM7OO61iykTRO0s8k3S/pPkkfzfFtJM2TtCD/3TrHJekCSX2S7pa0T2Fd0/L8CyRNK8T3lXRPXuaCfIZ63W2YmVl3dLJmsxI4PSJeRboy8CmS9gDOBK6LiAmkaxedmec/gnSm+QTShSMvgpQ4SBfs2590me+zC8njojxvdbkpOV5vG2Zm1gUdSzYRsTgi7sjPV5BulDSGdFOkmXm2maRLwZPjsyK5mXR11h2Bw4F5EbEsIp4g3ahoSp62ZUTcVLiMSXFdZdswM7MuGJY+G0njgdeQ7nK3Q0QshpSQSNfDgpSIipfj7s+xRvH+kjgNtlFbrumS5kuav3Tp0sHunpmZNdHxZJOvGHs1cFpELG80a0ksBhFvWURcHBGTImLS6NFNR+6ZmdkgdTTZSNqIlGi+HRHVq/AuyU1g5L+P5ng/a9+PYyzpSqqN4mNL4o22YWZmXdDJ0Wgi3Zfi/oj4YmHSHKA6omwa6XbB1fjxeVTaZOCp3AR2LekGSFvngQGHAdfmaSskTc7bOr5mXWXbaLvbHlrGF378AH9etbpTmzAzW+91smZzIOme2QdLuis/jiTdv+RQSQtId1w8L88/l3RP9T7SjbhOBoiIZcCngdvy41M5BnAS6R4dfcCDwI9yvN422u6O3z3Bl3/ax/MrnWzMzOrp2BUEIuIX1L+97SEl8wdwSp11zSDdzKk2Pp90L+/a+ONl2+iESk/axZWrfUFTM7N6fAWBIerNyWaVk42ZWV1ONkNUqaS3cOVqN6OZmdXjZDNE1ZqNc42ZWX1ONkO0ps/G2cbMrB4nmyFyn42ZWXNONkPk0WhmZs052QxRb096C12zMTOrz8lmiF6o2axysjEzq8fJZojcZ2Nm1pyTzRBVKh6NZmbWjJPNELlmY2bWnJPNEHk0mplZc042Q+TRaGZmzTnZDJFrNmZmzTnZDNGaPhsPEDAzq8fJZoh8no2ZWXOdvC30DEmPSrq3ELuicNfOhyTdlePjJf2xMO1rhWX2lXSPpD5JF+RbQCNpG0nzJC3If7fOceX5+iTdLWmfTu0jQG/Fo9HMzJrpZM3mMmBKMRAR746IiRExEbga+F5h8oPVaRHx4UL8ImA6MCE/qus8E7guIiYA1+XXAEcU5p2el++YXvfZmJk11bFkExE3AsvKpuXayTHA5Y3WIWlHYMuIuCnfNnoWcFSePBWYmZ/PrInPiuRmYFReT0dUPBrNzKypbvXZvAFYEhELCrFdJN0p6QZJb8ixMUB/YZ7+HAPYISIWA+S/2xeWebjOMmuRNF3SfEnzly5dOqgdcc3GzKy5biWb41i7VrMY2DkiXgN8DPiOpC0BlSzb7Fu95WUi4uKImBQRk0aPHt1CsddV8Wg0M7Omeod7g5J6gb8G9q3GIuI54Ln8/HZJDwKvINVKxhYWHwssys+XSNoxIhbnZrJHc7wfGFdnmbZzzcbMrLlu1GzeDPwmIl5oHpM0WlIlP9+V1Lm/MDePrZA0OffzHA9ckxebA0zLz6fVxI/Po9ImA09Vm9s6oeJro5mZNdXJoc+XAzcBu0vql3RinnQs6w4M+Cvgbkm/Aq4CPhwR1cEFJwGXAH3Ag8CPcvw84FBJC4BD82uAucDCPP83gJPbvW9F1cvV+DwbM7P6OtaMFhHH1Yl/oCR2NWkodNn884G9SuKPA4eUxAM4ZYDFHbSKz7MxM2vKVxAYIvfZmJk152QzRB6NZmbWnJPNEFXkmo2ZWTNONkPU0yN65D4bM7NGnGzaoLenxzUbM7MGnGzaoNIj12zMzBpwsmmD3h75PBszswacbNqgUpFHo5mZNeBk0wa9PXKfjZlZA042beA+GzOzxpxs2sCj0czMGnOyaQPXbMzMGnOyaQP32ZiZNeZk0wapZuPRaGZm9TjZtEHF59mYmTXkZNMGvRX32ZiZNdLJO3XOkPSopHsLsXMkPSLprvw4sjDtLEl9kh6QdHghPiXH+iSdWYjvIukWSQskXSFp4xzfJL/uy9PHd2ofqyoejWZm1lAnazaXAVNK4udHxMT8mAsgaQ/S7aL3zMt8VVJFUgW4EDgC2AM4Ls8L8Nm8rgnAE0D1ttMnAk9ExG7A+Xm+jur1aDQzs4Y6lmwi4kZgWYuzTwVmR8RzEfFboA/YLz/6ImJhRDwPzAamShJwMHBVXn4mcFRhXTPz86uAQ/L8HVPpESs9QMDMrK5u9NmcKunu3My2dY6NAR4uzNOfY/Xi2wJPRsTKmvha68rTn8rzd4xrNmZmjQ13srkIeDkwEVgMfCHHy2oeMYh4o3WtQ9J0SfMlzV+6dGmjcjdU8Xk2ZmYNDWuyiYglEbEqIlYD3yA1k0GqmYwrzDoWWNQg/hgwSlJvTXytdeXpW1GnOS8iLo6ISRExafTo0YPeL9dszMwaG9ZkI2nHwst3ANWRanOAY/NIsl2ACcCtwG3AhDzybGPSIII5ERHAz4Cj8/LTgGsK65qWnx8N/DTP3zGVnh6fZ2Nm1kBv81kGR9LlwEHAdpL6gbOBgyRNJDVrPQR8CCAi7pN0JfBrYCVwSkSsyus5FbgWqAAzIuK+vIkzgNmSPgPcCVya45cC35LUR6rRHNupfaxyzcbMrLGOJZuIOK4kfGlJrDr/ucC5JfG5wNyS+ELWNMMV438C3jWgwg5RpeLRaGZmjfgKAm3gmo2ZWWNONm3g0WhmZo052bSBazZmZo052bSBazZmZo052bSB79RpZtaYk00b9Pb0sHKVR6OZmdXjZNMGrtmYmTXmZNMGve6zMTNryMmmDSo9YnVnr4hjZrZec7JpA9dszMwac7Jpg0pPDxGw2gnHzKyUk00b9FbSLXRcuzEzK+dk0waVnpRsPCLNzKyck00b9PZUazY+18bMrIyTTRu4ZmNm1piTTRusqdk42ZiZlXGyaYNKT3obXbMxMyvXsWQjaYakRyXdW4j9h6TfSLpb0vcljcrx8ZL+KOmu/PhaYZl9Jd0jqU/SBZKU49tImidpQf67dY4rz9eXt7NPp/axyjUbM7PGOlmzuQyYUhObB+wVEa8G/g84qzDtwYiYmB8fLsQvAqYDE/Kjus4zgesiYgJwXX4NcERh3ul5+Y56oc9mlZONmVmZlpKNpM9J2lLSRpKuk/SYpPc1WiYibgSW1cR+HBEr88ubgbFNtrsjsGVE3BQRAcwCjsqTpwIz8/OZNfFZkdwMjMrr6Zg159l4NJqZWZlWazaHRcRy4K1AP/AK4B+HuO0PAj8qvN5F0p2SbpD0hhwbk7dX1Z9jADtExGKA/Hf7wjIP11lmLZKmS5ovaf7SpUsHvSMejWZm1liryWaj/PdI4PKIWNZo5mYk/ROwEvh2Di0Gdo6I1wAfA74jaUtAJYs3+0ZveZmIuDgiJkXEpNGjR7dW+BLuszEza6y3xfl+KOk3wB+BkyWNBv40mA1KmkaqIR2Sm8aIiOeA5/Lz2yU9SKo99bN2U9tYYFF+vkTSjhGxODeTPZrj/cC4Ost0hEejmZk11lLNJiLOBA4AJkXEn4FnSH0jAyJpCnAG8PaIeLYQHy2pkp/vSurcX5ibx1ZImpxHoR0PXJMXmwNMy8+n1cSPz6PSJgNPVZvbOsU1GzOzxlodIPAuYGVErJL0SeC/gJ2aLHM5cBOwu6R+SScCXwG2AObVDHH+K+BuSb8CrgI+XGiqOwm4BOgDHmRNP895wKGSFgCH5tcAc4GFef5vACe3so9DsabPxgMEzMzKtNqM9s8R8V1JrwcOBz5PGlK8f70FIuK4kvCldea9Gri6zrT5wF4l8ceBQ0riAZxSr1yd8ELNxkOfzcxKtTpAYFX++xbgooi4Bti4M0Va/3g0mplZY60mm0ckfR04BpgraZMBLDvi+X42ZmaNtZowjgGuBaZExJPANgz9PJsRw6PRzMwaa3U02rOkocWvz6GVwIJOFWp949FoZmaNtToa7WzSkOXqtcw2Io1IMzwazcysmVab0d4BvJ10fg0RsYg0hNlwzcbMrJlWk83zeUhxAEjarHNFWv94NJqZWWOtJpsr82i0UZL+FvgJ6YRJA3rzAAGfZ2NmVq6lkzoj4vOSDgWWA7sD/xIR8zpasvVIpeKajZlZI61eQYCcXJxgSrjPxsyssVZHo/11vv3yU5KWS1ohaXmnC7e+8Gg0M7PGWq3ZfA54W0Tc38nCrK9cszEza6zVAQJLnGjq82g0M7PGWq3ZzJd0BfAD8k3OACLiex0p1XrmhdFoTjZmZqVaTTZbAs8ChxViATjZ4JqNmVkzrSabSyLil8WApAM7UJ71ku9nY2bWWKt9Nl9uMbYWSTMkPSrp3kJsG0nz8ui2eZK2znFJukBSn6S7Je1TWGZann+BpGmF+L6S7snLXJBvHV13G53S0yMkj0YzM6unYbKRdICk04HRkj5WeJwDVFpY/2XAlJrYmcB1ETEBuC6/BjgCmJAf00l3AkXSNsDZpLuC7gecXUgeF+V5q8tNabKNjuntkftszMzqaFaz2RjYnNTctkXhsRw4utnKI+JGYFlNeCowMz+fCRxViM+K5GbSpXF2JN2Gel5ELIuIJ0gnlk7J07aMiJvyddtm1ayrbBsdU+mR+2zMzOpo2GcTETcAN0i6LCJ+16Zt7hARi/P6F0vaPsfHAA8X5uvPsUbx/pJ4o22sRdJ0Us2InXfeeSj7RG9Pj2s2ZmZ1NEw2kr4UEacBX5G0zjdpRLy9jWVRSSwGEW9ZRFwMXAwwadKkIWUK12zMzOprNhrtW/nv59u4zSWSdsw1jh1JdwCFVDMZV5hvLLAoxw+qiV+f42NL5m+0jY5JfTYeIGBmVqZZn81SSM1pZY9BbnMOUB1RNg24phA/Po9Kmww8lZvCrgUOk7R1HhhwGHBtnrZC0uQ8Cu34mnWVbaNjXLMxM6uvWbL5QfWJpKsHunJJlwM3AbtL6pd0InAecKikBcCh+TXAXGAh0Ee6V87JABGxDPg0cFt+fCrHAE4CLsnLPAj8KMfrbaNjenvk82zMzOpo1oxW7BfZdaArj4jj6kw6pGTeAE6ps54ZwIyS+Hxgr5L442Xb6KRKxTUbM7N6mtVsos5zq+HRaGZm9TWr2eyd71sjYNPCPWxEqoxs2dHSrUfcZ2NmVl+z82xauUqA4dFoZmaNNLtczXxJ/ylpiqSXDFeh1keu2ZiZ1desz2Yy8H3SeS43SJor6aOSXtHxkq1nfG00M7P6mjWjrSSdQHk9QD5B8gjgM5J2A26OiJM7XMb1gms2Zmb1Nb3FgKSKpP+AdJ2xiJgREccAk4Bvd7qA64venh6fZ2NmVkfTZBMRq4B9q/eKKcRX195QbUPmmo2ZWX2t3qnzTuAaSd8FnqkGI8K3hc4qPeK5lau6XQwzsxelVpPNNsDjwMGFWABONplrNmZm9bWUbCLihE4XZH3n0WhmZvU17bMBkDRW0vclPSppiaSrJY1tvuSGwzUbM7P6Wko2wDdJl+3fiXQ3zB/mmGW9FddszMzqaTXZjI6Ib0bEyvy4DBjdwXKtdyo9Pax2sjEzK9VqsnlM0vvyOTcVSe8jDRiwzH02Zmb1tZpsPggcA/wBWAwcnWOWuc/GzKy+pqPRJFWAd0bE24ehPOstX/XZzKy+Vq8gMLVdG5S0u6S7Co/lkk6TdI6kRwrxIwvLnCWpT9IDkg4vxKfkWJ+kMwvxXSTdImmBpCskbdyu8tfjmo2ZWX2tNqP9UtJXJL1B0j7Vx2A2GBEPRMTEiJgI7As8S7qyNMD51WkRMRdA0h7AscCewBTgq9W+I+BC0oVB9wCOy/MCfDavawLwBHDiYMo6EO6zMTOrr9UrCLwu//1UIRasfUWBwTgEeDAifldz6bWiqcDsiHgO+K2kPmC/PK0vIhYCSJoNTJV0fy7Xe/I8M4FzgIuGWNaGKj09rPKFOM3MSrXSZ9MDXBQRV3Zg+8cClxdenyrpeGA+cHpEPEE6r+fmwjz9OQbwcE18f2Bb4Ml8e4Ta+dciaTowHWDnnXce0o74PBszs/pa6bNZDZza7g3nfpS3A9/NoYuAlwMTSSPevlCdtaxYg4ivG4y4OCImRcSk0aOHdtqQ+2zMzOprtc9mnqR/kDRO0jbVxxC3fQRwR0QsAYiIJRGxKie3b7CmqawfGFdYbiywqEH8MWCUpN6aeEd5NJqZWX0DOc/mFOBG4Pb8mD/EbR9HoQkt3wW06h3Avfn5HOBYSZtI2gWYANwK3AZMyCPPNiY1yc2JiAB+RjoXCGAacM0Qy9pUpUesDnwVATOzEq1e9XmXdm5U0kuBQ4EPFcKfkzSR1OT1UHVaRNwn6Urg18BK4JQ8HBtJpwLXAhVgRkTcl9d1BjBb0mdI9+K5tJ3lL9Pbk1rvVkXQU9qSZ2a24WqYbCR9PCI+l5+/KyK+W5j2bxHxicFsNCKeJXXkF2PvbzD/ucC5JfG5wNyS+ELWNMMNi0pPqiSuWh1sVBnOLZuZvfg1a0Y7tvD8rJppU9pclvVatWbjEWlmZutqlmxU53nZ6w1apdqM5nNtzMzW0SzZRJ3nZa83aL2Vas3GI9LMzGo1GyCwt6TlpFrMpvk5+fVLOlqy9cwLNRs3o5mZraNhsokId3W3yH02Zmb1tXqejTVRHI1mZmZrc7JpE9dszMzqc7JpkzV9Nh4gYGZWy8mmTVyzMTOrz8mmTao1m5U+z8bMbB1ONm1SPc/GAwTMzNblZNMm1dFobkYzM1uXk02b9PqkTjOzupxs2uSFPhuPRjMzW4eTTZu4ZmNmVp+TTZtUPPTZzKyuriUbSQ9JukfSXZLm59g2kuZJWpD/bp3jknSBpD5Jd0vap7CeaXn+BZKmFeL75vX35WU7ekuE3urlajz02cxsHd2u2bwpIiZGxKT8+kzguoiYAFyXXwMcAUzIj+nARZCSE3A2sD/pzpxnVxNUnmd6YbmO3uzNNRszs/q6nWxqTQVm5uczgaMK8VmR3AyMkrQjcDgwLyKWRcQTwDxgSp62ZUTcFBEBzCqsqyN8no2ZWX3dTDYB/FjS7ZKm59gOEbEYIP/dPsfHAA8Xlu3PsUbx/pL4WiRNlzRf0vylS5cOaWc8Gs3MrL5mN0/rpAMjYpGk7YF5kn7TYN6y/pYYRHztQMTFwMUAkyZNGlKVxKPRzMzq61rNJiIW5b+PAt8n9bksyU1g5L+P5tn7gXGFxccCi5rEx5bEO8Z9NmZm9XUl2UjaTNIW1efAYcC9wBygOqJsGnBNfj4HOD6PSpsMPJWb2a4FDpO0dR4YcBhwbZ62QtLkPArt+MK6OqLXN08zM6urW81oOwDfz6ORe4HvRMT/SLoNuFLSicDvgXfl+ecCRwJ9wLPACQARsUzSp4Hb8nyfiohl+flJwGXApsCP8qNjXLMxM6uvK8kmIhYCe5fEHwcOKYkHcEqddc0AZpTE5wN7DbmwLXqhz2aVBwiYmdV6sQ19Xm9VKq7ZmJnV42TTJh6NZmZWn5NNm7jPxsysPiebNvFoNDOz+pxs2iRXbFyzMTMr4WTTJpLo7RGrfLkaM7N1ONm0UaVHrtmYmZVwsmmj3h5Y+T2AAAAK10lEQVT5fjZmZiWcbNrINRszs3JONm3UW+nxaDQzsxJONm3kmo2ZWTknmzbyaDQzs3JONm3kmo2ZWTknmzZKNRsnGzOzWk42bdTjmo2ZWSknmzbyeTZmZuWGPdlIGifpZ5Lul3SfpI/m+DmSHpF0V34cWVjmLEl9kh6QdHghPiXH+iSdWYjvIukWSQskXSFp4+HYt0pPj2s2ZmYlulGzWQmcHhGvAiYDp0jaI087PyIm5sdcgDztWGBPYArwVUkVSRXgQuAIYA/guMJ6PpvXNQF4AjhxOHast0esDicbM7Naw55sImJxRNyRn68A7gfGNFhkKjA7Ip6LiN8CfcB++dEXEQsj4nlgNjBVkoCDgavy8jOBozqzN2vzaDQzs3Jd7bORNB54DXBLDp0q6W5JMyRtnWNjgIcLi/XnWL34tsCTEbGyJl62/emS5kuav3Tp0iHvj8+zMTMr17VkI2lz4GrgtIhYDlwEvByYCCwGvlCdtWTxGER83WDExRExKSImjR49eoB7sK5Kj1jpAQJmZuvoSrKRtBEp0Xw7Ir4HEBFLImJVRKwGvkFqJoNUMxlXWHwssKhB/DFglKTemnjH9VZ8no2ZWZlujEYTcClwf0R8sRDfsTDbO4B78/M5wLGSNpG0CzABuBW4DZiQR55tTBpEMCciAvgZcHRefhpwTSf3qcqj0czMyvU2n6XtDgTeD9wj6a4c+wRpNNlEUpPXQ8CHACLiPklXAr8mjWQ7JSJWAUg6FbgWqAAzIuK+vL4zgNmSPgPcSUpuHecrCJiZlRv2ZBMRv6C8X2Vug2XOBc4tic8tWy4iFrKmGW7YeDSamVk5X0GgjTwazcysnJNNG7lmY2ZWzsmmjdxnY2ZWzsmmjSo9PT7PxsyshJNNG7lmY2ZWzsmmjSoV99mYmZVxsmkjj0YzMyvnZNNGHo1mZlbOyaaN3GdjZlbOyaaNfG00M7NyTjZt5JqNmVk5J5s2quRkE741tJnZWpxs2qi3J11f1LUbM7O1Odm0UaWSko37bczM1uZk00au2ZiZlXOyaaNKT3o7XbMxM1ubk00buWZjZlZuxCYbSVMkPSCpT9KZw7HNSk+1z8aXrDEzKxr220IPB0kV4ELgUKAfuE3SnIj4dSe3u1EeIPDWC37xQi2nUhG9PT1UelR6L2wzs277yCETeNveO3V0GyMy2QD7AX0RsRBA0mxgKtDRZPPGV2zPe/ffmedXpppNAKtXBytXh2s7ZvaitdWmG3V8GyM12YwBHi687gf2r51J0nRgOsDOO+885I3+xVYv4dx3/OWQ12NmNtKM1D6bshardXrtI+LiiJgUEZNGjx49DMUyM9swjdRk0w+MK7weCyzqUlnMzDZ4IzXZ3AZMkLSLpI2BY4E5XS6TmdkGa0T22UTESkmnAtcCFWBGRNzX5WKZmW2wRmSyAYiIucDcbpfDzMxGbjOamZm9iDjZmJlZxznZmJlZx8l3lUwkLQV+N4BFtgMe61BxXsw2xP3eEPcZNsz93hD3GYa23y+LiKYnKjrZDJKk+RExqdvlGG4b4n5viPsMG+Z+b4j7DMOz325GMzOzjnOyMTOzjnOyGbyLu12ALtkQ93tD3GfYMPd7Q9xnGIb9dp+NmZl1nGs2ZmbWcU42ZmbWcU42gyBpiqQHJPVJOrPb5ekESeMk/UzS/ZLuk/TRHN9G0jxJC/Lfrbtd1naTVJF0p6T/zq93kXRL3ucr8pXERxRJoyRdJek3+ZgfsIEc67/Pn+97JV0u6SUj7XhLmiHpUUn3FmKlx1bJBfm77W5J+7SrHE42AySpAlwIHAHsARwnaY/ulqojVgKnR8SrgMnAKXk/zwSui4gJwHX59UjzUeD+wuvPAufnfX4COLErpeqs/wT+JyJeCexN2v8RfawljQE+AkyKiL1IV4g/lpF3vC8DptTE6h3bI4AJ+TEduKhdhXCyGbj9gL6IWBgRzwOzgaldLlPbRcTiiLgjP19B+vIZQ9rXmXm2mcBR3SlhZ0gaC7wFuCS/FnAwcFWeZSTu85bAXwGXAkTE8xHxJCP8WGe9wKaSeoGXAosZYcc7Im4EltWE6x3bqcCsSG4GRknasR3lcLIZuDHAw4XX/Tk2YkkaD7wGuAXYISIWQ0pIwPbdK1lHfAn4OLA6v94WeDIiVubXI/F47wosBb6Zmw8vkbQZI/xYR8QjwOeB35OSzFPA7Yz84w31j23Hvt+cbAZOJbERO35c0ubA1cBpEbG82+XpJElvBR6NiNuL4ZJZR9rx7gX2AS6KiNcAzzDCmszK5H6KqcAuwE7AZqRmpFoj7Xg30rHPu5PNwPUD4wqvxwKLulSWjpK0ESnRfDsivpfDS6rV6vz30W6VrwMOBN4u6SFS8+jBpJrOqNzMAiPzePcD/RFxS359FSn5jORjDfBm4LcRsTQi/gx8D3gdI/94Q/1j27HvNyebgbsNmJBHrGxM6lCc0+UytV3uq7gUuD8ivliYNAeYlp9PA64Z7rJ1SkScFRFjI2I86bj+NCLeC/wMODrPNqL2GSAi/gA8LGn3HDoE+DUj+FhnvwcmS3pp/rxX93tEH++s3rGdAxyfR6VNBp6qNrcNla8gMAiSjiT94q0AMyLi3C4Xqe0kvR74OXAPa/ovPkHqt7kS2Jn0z/quiKjtfFzvSToI+IeIeKukXUk1nW2AO4H3RcRz3Sxfu0maSBoUsTGwEDiB9GN0RB9rSf8KvJs0+vJO4G9IfRQj5nhLuhw4iHQbgSXA2cAPKDm2Oel+hTR67VnghIiY35ZyONmYmVmnuRnNzMw6zsnGzMw6zsnGzMw6zsnGzMw6zsnGzMw6zsnGbJAk7SDpO5IWSrpd0k2S3tGlshwk6XWF1x+WdHw3ymJWprf5LGZWK5+P8ANgZkS8J8deBry9g9vsLVyzq9ZBwNPA/wJExNc6VQ6zwfB5NmaDIOkQ4F8i4o0l0yrAeaQEsAlwYUR8PZ8oeg7wGLAX6aKP74uIkLQv8EVg8zz9AxGxWNL1pARyIOns7v8DPkk6+fJx4L3ApsDNwCrSBTX/jnQ2/NMR8fl8wubXSFc1fhD4YEQ8kdd9C/AmYBRwYkT8vH3vktkabkYzG5w9gTvqTDuRdJmP1wKvBf5W0i552muA00j3QtoVODBfg+7LwNERsS8wAyhelWJURLwxIr4A/AKYnC+YORv4eEQ8REom50fExJKEMQs4IyJeTboixNmFab0RsV8u09mYdYib0czaQNKFwOuB54HfAa+WVL2+1lakm1E9D9waEf15mbuA8cCTpJrOvNQ6R4V0yfuqKwrPxwJX5Isnbgz8tkm5tiIlqxtyaCbw3cIs1Qus3p7LYtYRTjZmg3Mf8M7qi4g4RdJ2wHzStab+LiKuLS6Qm9GK19haRfofFHBfRBxQZ1vPFJ5/GfhiRMwpNMsNRbU81bKYdYSb0cwG56fASySdVIi9NP+9FjgpN48h6RX5ZmT1PACMlnRAnn8jSXvWmXcr4JH8fFohvgLYonbmiHgKeELSG3Lo/cANtfOZdZp/yZgNQu7UPwo4X9LHSR3zzwBnkJqpxgN35FFrS2lwa+GIeD43uV2Qm716SVcVv69k9nOA70p6hDQooNoX9EPgKklTSQMEiqYBX5P0UtZc0dlsWHk0mpmZdZyb0czMrOOcbMzMrOOcbMzMrOOcbMzMrOOcbMzMrOOcbMzMrOOcbMzMrOP+P59/2Hk7OtyOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best solution is [ 0.57171434 -0.62732547 43.0080016 ]\n",
      "with error equal to approximately 920.0131978387623\n"
     ]
    }
   ],
   "source": [
    "### Genetic algorithm to fit a regression line of the form y= a + b1x1 + b2x2 to a \n",
    "#3-variable dataset\n",
    "\n",
    "#packages - same as before\n",
    "import random\n",
    "import numpy as np\n",
    "from numpy.random import choice\n",
    "from matplotlib.pylab import plt #package for plotting \n",
    "\n",
    "my_second_file = 'created_multiple_regression_data.npy' #I created a new dataset \n",
    "#in the format of a npy file with three columns, 100 rows and numbers from -1 to 80 \n",
    "#(including) called \"created_multiple_regression_data.npy\". \n",
    "data_mul_reg = np.load(my_second_file) #loading the dataset\n",
    "\n",
    "# parameters - same as before\n",
    "initial_pop_size = 100\n",
    "mutation_rate = 0.05\n",
    "num_generations = 100\n",
    "chromosome_length = 3\n",
    "num_survivors = 50\n",
    "\n",
    "#same as before\n",
    "def A():\n",
    "    gene_pool = np.linspace(-1,80,num = 5000)\n",
    "    dimensions = (initial_pop_size, chromosome_length)\n",
    "    return np.random.choice(gene_pool, size=dimensions, replace=False)\n",
    "\n",
    "#edited\n",
    "def B(coefficients):\n",
    "    k = len(data_mul_reg)\n",
    "    tot = 0\n",
    "\n",
    "    for j in range(k):\n",
    "        y = (coefficients[0] * data_mul_reg[j,0]) + (coefficients[1] * \\\n",
    "        data_mul_reg[j,1]) + coefficients[2] #the function \n",
    "        #for calculating the y-values know incorporates the extra variable. \n",
    "        res = data_mul_reg[j,2] - y #moving the index to the right column \n",
    "        #with the y-values. \n",
    "        tot += res**2\n",
    "    return tot/k\n",
    "\n",
    "#same as before\n",
    "def C():\n",
    "    fitlist = []\n",
    "    for x in range(len(current_pop)):\n",
    "        fitlist.append(np.array([x,B(current_pop[x])])) \n",
    "\n",
    "    return np.array(fitlist)\n",
    "\n",
    "#same as before\n",
    "def D():\n",
    "    random_selection = np.random.choice(range(len(fitness_vector)), \\\n",
    "    num_survivors//2, replace=False)\n",
    "    best = np.argmin(fitness_vector[random_selection,1])\n",
    "    best_index = random_selection[best]\n",
    "    return current_pop[int(fitness_vector[best_index][0])]    \n",
    "\n",
    "#same as before\n",
    "def E():\n",
    "    duplicate_size = len(new_population) - len(survivors)\n",
    "    duplicate_survivors = np.zeros((duplicate_size, chromosome_length))\n",
    "    for x in range(chromosome_length): \n",
    "        duplicate_survivors[:, x] = np.repeat(survivors[:, x], 4, axis=0) \n",
    "        duplicate_survivors[:, x] = np.random.permutation(duplicate_survivors[:, x])\n",
    "    return duplicate_survivors\n",
    "\n",
    "#same as before\n",
    "def F(array):\n",
    "    \n",
    "    elements = [0, 1]\n",
    "    weights = [1 - mutation_rate, mutation_rate]\n",
    "\n",
    "    numrows = (len(array))\n",
    "    numcolumns = (len(array[0]))\n",
    "    \n",
    "    for i in range((len(array))):\n",
    "        \n",
    "        for j in range((len(array[0]))):\n",
    "\n",
    "            mutate_number = choice(elements, p = weights) \n",
    "        \n",
    "            if mutate_number == 1:\n",
    "            \n",
    "                original_value = array[i, j]\n",
    "\n",
    "                random_index1 = np.random.randint(0, numrows)\n",
    "                random_index2 = np.random.randint(0, numcolumns)\n",
    "\n",
    "                random_value = array[random_index1, random_index2]\n",
    "\n",
    "                array[i,j] = random_value\n",
    "\n",
    "                array[random_index1, random_index2] = original_value\n",
    "\n",
    "    return array\n",
    "\n",
    "########################################################################\n",
    "# Start of main program - same as before\n",
    "current_pop = A()\n",
    "new_population = np.zeros((num_survivors * 5, chromosome_length))\n",
    "\n",
    "count = 0\n",
    "fitness_x = []\n",
    "fitness_y = []\n",
    "\n",
    "# main loop\n",
    "for i in range(num_generations):\n",
    "    \n",
    "    fitness_vector = C()\n",
    "    survivors = np.zeros((num_survivors, chromosome_length))\n",
    "    for n in range(len(survivors)):\n",
    "        survivors[n] = D()\n",
    "    new_population[:len(survivors)] = survivors\n",
    "    new_population[len(survivors):] = E()\n",
    "    \n",
    "    new_population = F(new_population)\n",
    "    \n",
    "    current_pop = new_population\n",
    "    new_population = np.zeros((num_survivors * 5, chromosome_length))\n",
    "    \n",
    "    current_best_index = np.argmin(fitness_vector[:,1])\n",
    "    current_best_fitness = fitness_vector[current_best_index,1]\n",
    "    \n",
    "    count += 1\n",
    "    fitness_x.append(count)\n",
    "    fitness_y.append(current_best_fitness)\n",
    "\n",
    "plt.plot(fitness_x, fitness_y,)\n",
    "plt.ylabel(\"Error/Fitness\")\n",
    "plt.xlabel(\"Generation\")\n",
    "plt.title(\"Error/Fitness Value Change for Each Generation\")\n",
    "plt.show()    \n",
    "\n",
    "fitness_vector = C()\n",
    "best_solution = current_pop[np.argmin(fitness_vector[:,1])]\n",
    "print(\"The best solution is\", best_solution)\n",
    "print(\"with error equal to approximately\", B(best_solution))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b1 and b2 = [[ 0.00347563 -0.05835841]]\n",
      "a = [[41.9436013]]\n"
     ]
    }
   ],
   "source": [
    "#importing packages to find the optimal regression line with a build-in function.\n",
    "from sklearn import linear_model\n",
    "\n",
    "reg = linear_model.LinearRegression() #using the linear_model.LinearRegression() \n",
    "#function to do multiple regression. \n",
    "reg.fit(data_mul_reg[:,:2], data_mul_reg[:,2:3]) #setting the x- and y-columns. \n",
    "the_coefficients = reg.coef_ #finding the regression coefficients.\n",
    "print(\"b1 and b2 =\", reg.coef_) #printing the value of b1 and b2.\n",
    "\n",
    "first_term = the_coefficients[:,:1] #pulling the value of b1.\n",
    "second_term = the_coefficients[:,1:] #pulling the value of b2.\n",
    "\n",
    "#comouting the error term (a) as the build-in function does not include it.\n",
    "mean_Y = np.mean(data_mul_reg[:,-1]) #finding the mean of the y-values. \n",
    "\n",
    "a = mean_Y - (first_term * data_mul_reg[0,0]) - (second_term * data_mul_reg[0,1]) \n",
    "#finding the a term through the formula a = Y_mean - (b1 * X1) - (b2 * X2).\n",
    "\n",
    "print(\"a =\", a) #printing the value of a."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S61T1sA0i9p7"
   },
   "source": [
    "#### 4.2 Write your own genetic algorithm from scratch to find the regression line for a two-variable dataset, using different data structures and different functions than the code provided. This requires thorough explanation, sufficiently detailed so that another student could understand your algorithm.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jxEQlSmVi9p9"
   },
   "source": [
    "Edit this cell to answer part 4.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I_GvHFjqi9p_"
   },
   "source": [
    "#### 4.3 Write your own algorithm to find the line of best fit for a two-variable dataset using a perceptron. As above, the explanations of your code need to be sufficiently detailed so that another student could understand it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yFCx8_msi9p_"
   },
   "source": [
    "Edit this cell to answer part 4.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "08MD-DVzi9qA"
   },
   "source": [
    "## Part 2: Lotka-Volterra Simulation\n",
    "\n",
    "In this portion of the assignment, you will produce code that uses Euler’s method to implement a simulation of the solutions of the Lotka-Volterra equations. In addition to providing more practice in Python programming, this project challenges you to understand numerical methods for solving differential equations, which will lead to a deeper understanding of these models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JqPEjbSwi9qA"
   },
   "source": [
    "### 1. Simulation Code [#algorithms, #simulation, #variables, #dataviz]\n",
    "\n",
    "Write code that inputs the initial ($t=0$) populations for predator and prey, parameter values, desired final output time, and time-step size ($h$), and outputs graphs of both predator and prey populations at each time-step on the same plot; final predicted population sizes for both predator and prey. \n",
    "\n",
    "* Write comments for each function you define, specifying inputs and outputs, along with a brief description of what the function does.\n",
    "* Consider your initial parameter inputs. Explain how the result changes as you vary the initial parameters. Can you find a set of initial parameters that produce stable cyclic population dynamics? Explain the significance of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final predicted prey population size = 0\n",
      "Final predicted predators population size = 170.81\n",
      "[10, 20.0, 22.0, -55.22000000000001]\n",
      "[10, 19.0, 55.1, 170.81000000000003]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np #importing necessary packages. \n",
    "from matplotlib.pylab import plt #package for plotting \n",
    "\n",
    "#defining a function which takes the inputs: initial prey population, initial \n",
    "#predator population, initial time final time, step size, and the parameters \n",
    "#alpha, beta, delta and gamma. It outputs the predicted prey and predator \n",
    "#population after the specified time along with a grapf of the populations. \n",
    "def euler(prey_start, predator_start, it, ft, step_size, a, b, d, g):\n",
    "    \n",
    "    timestamps = [] #generating a list for each timestamp\n",
    "    timestamps.append(it) #appending the initial time to the timestamp list\n",
    "    \n",
    "    prey = [] #generating a list for the number of prey at each timestamp\n",
    "    predator = [] #generating a list for the number of predator at each timestamp\n",
    "    \n",
    "    prey.append(prey_start) #appending the initial number of prey to the prey list\n",
    "    predator.append(predator_start) #appending the initial number of predator to \n",
    "    #the predator list.\n",
    "    \n",
    "    #using a while loop to ensure that the function iterates as long as the final \n",
    "    #time has not been reached (most recent timestamp < final time). Also, if \n",
    "    #either the prey or predator populations become less than zero it will stop \n",
    "    #iterating (as a population cannot be negative).\n",
    "    while timestamps[-1] <= ft and prey[-1] > 0 and predator[-1] > 0:\n",
    "        \n",
    "        #finding the new prey and predator number with the use of Euler's method. \n",
    "        #[-1] indicates that the last element of either the prey or predator \n",
    "        #list is used to find the new one. \n",
    "        prey_n = prey[-1] + (((a * prey[-1]) - (b * prey[-1] * predator[-1]))*step_size)\n",
    "        predator_n = predator[-1] + (((d * prey[-1] * predator[-1]) + ((-g) * predator[-1]))*step_size)\n",
    "        \n",
    "        #appending the new prey and predator numbers to their respective lists. \n",
    "        prey.append(prey_n)\n",
    "        predator.append(predator_n)\n",
    "        \n",
    "        #computing the new time to ensure that the while loop will not run \n",
    "        #infinitely.\n",
    "        new_time = timestamps[-1] + step_size    \n",
    "        #appending the new time to the timestamp list. \n",
    "        timestamps.append(new_time)\n",
    "    \n",
    "    #plotting the timestamp vs. the prey along with predator numbers and \n",
    "    #formatting the graph. \n",
    "    plt.plot(timestamps, prey, label = \"Number of Prey\")\n",
    "    plt.plot(timestamps, predator, label = \"Number of Predator\")\n",
    "    plt.ylabel(\"Population\")\n",
    "    plt.ylim(0)\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.title(\"Number of Prey and Predators over Time\")\n",
    "    legend =plt.legend(loc=\"upper left\", shadow=False, fontsize=\"large\")\n",
    "    plt.show()\n",
    "    \n",
    "    #if the last number in the prey list is negative it will output that the \n",
    "    #population is zero (as populations cannot be negative). Otherwise, \n",
    "    #it will output the predicted prey population.\n",
    "    if prey[-1] < 0:\n",
    "        print(\"Final predicted prey population size = 0\")\n",
    "    else:\n",
    "        print (\"Final predicted prey population size =\", '%.2f' % prey[-1]) \n",
    "        #rounding the number to an integer as there cannot be e.g. half a prey. \n",
    "    \n",
    "    #same as a above just for the predator population. \n",
    "    if predator[-1] < 0:\n",
    "        print(\"Final predicted predator population size = 0\")\n",
    "    else:\n",
    "        print(\"Final predicted predators population size =\", '%.2f' % predator[-1]) \n",
    "        #rounding as above.\n",
    "    \n",
    "    print(prey)\n",
    "    print(predator)\n",
    "\n",
    "#calling the function\n",
    "euler(10, 10, 0, 5, 0.1, 20, 1, 1, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis of Results and Parameters:**\n",
    "\n",
    "The results of the model can change drastically depending on the initial parameters. For many sets of the initial parameters, the preys take over, or both the preys and the predators die before the simulation reaches the desired final time. When the alpha = 1.1, beta = 0.4, delta = 0.1, and gamma = 0.4 and the initial prey and predator populations are e.g. equal to 10, it is possible to see a cyclical population pattern. \n",
    "\n",
    "This pattern is significant because it means that neither the prey or predator are going extinct over time. As a result, the outcome corresponds to what it hypothesized about prey and predator populations: as the predator population increases, the consumption of prey also increases. However, at one point there will not be enough prey for the predators which means that the population of the latter will decrease allowing for the prey population to grow again. Thus, the cyclical pattern continues. However, the simulation does have the limitation that it can calculate with values other than integers which means that the output prey and predator numbers might not be whole (although we cannot, e.g., have half a prey). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rP3dQlgDi9qF"
   },
   "source": [
    "### 2. Simulation Analysis [#simulation, #modeling]: \n",
    "\n",
    "Write a 500-word paper analyzing this simulation and comparing/contrasting it with the NetLogo Wolf Sheep Predation model from class. Address the following points in your write-up:\n",
    "\n",
    "a) Are there any differences between the assumptions of the Lotka-Volterra model and the assumptions of your simulation? For example, consider whether the model and simulation are continuous or discrete.\n",
    "\n",
    "b) How does your simulation contrast with an analytical approach to deriving the implications of the Lotka-Volterra model?\n",
    "\n",
    "c) Compare and contrast your simulation with the NetLogo Wolf Sheep Predation simulation.\n",
    "\n",
    "* Is each simulation stochastic or deterministic?\n",
    "* Do they have differing assumptions?\n",
    "* Do they give differing results?\n",
    "* Which of them seems to be a more realistic representation of nature? Why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3oWy1Aqhi9qG"
   },
   "source": [
    "**Analysis:**\n",
    "\n",
    "The Lotka-Volterra model has many assumptions such as not taking environmental factors into account. As a result, it assumes that the prey population has no shortage of food, that it has no other threat than the single predator, and that it will grow exponentially when there are no predators. For the predator, it is assumed that they only eat this single prey. Also, for both of the agents, it is assumed that the parameters for birth, growth, death, eating are constant (Blaszak, n.d.). \n",
    "   \n",
    "Similarly, the simulation also relies on these assumptions since it is built with the use of the Lotka-Volterra equations. However, there are still some differences. The model is continuous as it is possible to input any time. On the other hand, the simulation is discrete because it relies on a step size which means that the variables only take on countable values. \n",
    "\n",
    "Different implications can be derived from taking an analytical approach versus using the simulation. The analytic approach involves using only theoretical and mathematical methods which allows one to arrive at an actual answer and being able to generate a continuous graph of infinite numbers on the desired interval. Conversely, the simulation approximates the answer by estimating new points based on previous points. As a result, using the simulation will create a discrete graph where errors will be involved. However, one can lessen the error by using a smaller step size as this would generate more points.  \n",
    "\n",
    "Another simulation that also models the prey versus predator populations is the NetLogo Wolf Sheep Predator simulation. The NetLogo model is stochastic because it uses a random generator to model different outputs which is evident by the use of “random” in the code of the simulation. On the other hand, the Lotka-Volterra simulation is deterministic because running the code several times will give the same output. The latter is also evident because the random module has not been used in the code.    \n",
    "\n",
    "The two simulations rely on different assumptions since they have different parameters. Whereas the Lotka-Volterra simulations built on assumptions about the general populations, the NetLogo simulation relies on rules for the individual prey and predator. However, the latter still has the underlying assumptions of no environmental factors and that the prey and predator follow simple rules. Still, in the NetLogo simulation, it is possible to add another parameter that specifies that sheep must eat grass to survive which makes the simulation more realistic. Since the two simulations have different parameters, it also means that they can generate different results. In general, it can be hard to precisely compare their outputs because of not having the ability to compare their parameters directly. \n",
    "\n",
    "Overall, the NetLogo simulation seems more realistic because it accounts for behavior at the individual level and does not try to generalize system behavior. Still, both simulations rely on simple rules and assumptions which are highly unrealistic. Thus, the models might be used to get a sense of the pattern for a single prey and predator, but additional parameters would be needed to model a real-life situation more precisely. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OzIXVBfHi9qI"
   },
   "source": [
    "### 3. Optional [#simulation, #modeling]: \n",
    "\n",
    "In the following resource, read the back story on slide 3 and the explanation provided on slide 14. Then, modify your code above to examine the explanation given for why the number of predatory fishes increased after WWI. How do your simulated results compare to the analytical explanation? \n",
    "\n",
    "Sternberg, S. (2009). Lecture 15 Lotka-Volterra. Retrieved from http://www.math.harvard.edu/library/sternberg/slides/11809LV.pdf.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DS6Irh7Wi9qM"
   },
   "source": [
    "## Reflection \n",
    "\n",
    "Describe how you obtained the knowledge to complete the assignment, being sure to include attributions to specific individuals or groups who helped you and how they helped. You should elaborate on any strategies you used to assess your own understanding of the material. [#selfawareness] (<100 words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DWKMQQY_i9qN"
   },
   "source": [
    "**Relection:**\n",
    "\n",
    "For the first task, I discussed the general understanding of the algorithm with Ananda, Ella, and Dima. Furthermore, I used a Numpy manual to understand some of the functions. For the mutation code, I assessed my understanding of the material by not finding a mutation code online but instead coding it from scratch (similar for the optional challenges). \n",
    "\n",
    "For part two, I started by writing the code in natural English to determine the necessary components. Then, I wrote the code while using print statements to check it. After trying to reach a cyclical pattern with different combinations of the initial inputs, I consulted Wikipedia. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References:**\n",
    "\n",
    "Blaszak, T. (n.d.). Lotka-Volterra models of Predator-Prey Relationships. Retrieved March 2, 2019, from http://web.mst.edu/~huwen/teaching_Predator_Prey_Tyler_Blaszak.pdf\n",
    "\n",
    "Lotka–Volterra equations. (2019, February 15). Retrieved March 3, 2019, from https://en.wikipedia.org/wiki/Lotka–Volterra_equations\n",
    "\n",
    "NumPy v1.16 Manual. (n.d.). Retrieved March 3, 2019, from https://docs.scipy.org/doc/numpy/index.html"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Assignment 2 Algorithms and Simulation Spring 2019 Notebook.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
